This web application provides a detailed visual analysis of a software team's activity using data from a Jira-like system. Its purpose is to highlight developer capacity, time estimation accuracy, sprint progress, and overall team efficiency through a series of interactive charts generated with the Highcharts library.  
The application automatically connects to a public API that provides a JSON structure containing tasks. The data is retrieved from the following link:  
https://gist.githubusercontent.com/ai-cristea/95bf91857a4cbe138595ea6876c441f2/raw/date-jira.json

I found tasks marked as "To Do" that already had hours logged, so I normalized the data by assuming these tasks were actually "In Progress".

This solution is useful both for retrospective analysis of team performance and for identifying potential improvements in management, workload distribution, and time estimation.

## Chart Summary

| # | Chart Title                             | Calculates                                                                                       | Interpretation |
|---|------------------------------------------|--------------------------------------------------------------------------------------------------|----------------|
| 1 | Task Status Distribution per Developer   | The number and share of `To Do`, `In Progress`, and `Done` tasks for each developer.            | Alice is slightly overloaded. John has too many active tasks and may face delays. Michael has a good balance between ongoing work and completed tasks. |
| 2 | Task Type Distribution per Developer     | The distribution of task types (Bug, Story, Task) for each developer.                           | Alice and John have a varied workload, but mostly focused on bugs. Michael works exclusively on Story and Bug, with no general tasks – which may indicate specialization or limited allocation. |
| 3 | Estimation Accuracy (Actual ≤ Estimated) | The percentage of completed tasks (out of each developer’s total done tasks) where the actual time worked was less than or equal to the estimated time. | Michael has always met his estimates (100%), Alice's estimates are fairly accurate (75%), while John has never stayed within the estimated time. |
| 4 | Underestimated Tasks (Actual > Estimated)| The percentage of completed tasks (out of each developer’s total done tasks) where the actual time worked exceeded the initial estimate. | John consistently underestimates (100%) – a major risk for delays. Alice occasionally underestimates (25%). Michael always stays within estimates. |
| 5 | Mean Estimation Error per Developer      | The average percentage error between estimated and actual time for completed tasks (Done) — positive means underestimation, negative means overestimation. | John has a high error rate (+60%) – unrealistic estimates. Alice is close to ideal (+7%), while Michael tends to estimate conservatively (−2%). |
| 6 | Estimation Error by Task Type            | The average estimation error grouped by task type (Bug, Story, Task) for each developer, based only on Done tasks. This helps identify where developers may struggle with accurate estimation. | Alice underestimates Bug tasks but overestimates Story and Task. John shows high error rates across all types. Michael provides very accurate estimates. |
| 7 | Estimation Risk for In Progress Tasks    | The percentage of In Progress tasks that have already exceeded their estimated time versus those still within estimate. The goal is to identify which developer is at highest risk of missing deadlines. | Alice and Michael have a low risk (less than 20% of tasks over estimate). John has a high risk – 75% of his tasks have already exceeded the estimate. |
| 8 | Average Closure Time (Done Tasks)        | The average number of days needed to close a Done task.                                          | All developers complete a task in 2–3 days. |
| 9 | Time Estimates – Done Tasks              | Estimated hours vs. actual hours worked for each completed task.                                | Helps fine-tune estimations and understand deviations. It can highlight task types that tend to exceed their estimates. |
|10 | Time Estimates – In Progress Tasks       | Estimated hours vs. hours logged so far for each In Progress task.                              | Provides insight into the current work pace. Tasks where actual > estimated may already require immediate attention. |
|11 | Member Contribution per Sprint           | The percentage of tasks in each sprint worked on by each team member.                           | All members contributed equally (33.3%) – the workload is perfectly balanced across all sprints. |
|12 | Developer Workload Share per Sprint      | The percentage of total hours worked in each sprint, for task done or in progress, distributed per developer. | Tasks are evenly distributed among team members in each sprint. However, in sprints 2–4, John appears to register a higher number of hours, which may suggest that his tasks were more complex or time-consuming. |
|13 | Average Estimation Error per Sprint      | The average percentage estimation error of Done tasks within each sprint.                       | Helps assess the quality of sprint planning. Large jumps between sprints may indicate fluctuations in task difficulty or inconsistency in estimations. The team started with inaccurate estimates (Sprint 1), but corrected course in the following sprints. |
|14 | Unfinished Tasks per Sprint              | The percentage of tasks not completed by the end of the sprint.                                  | Sprints with many unfinished tasks may indicate overestimation of the team’s capacity or execution issues. |
|15 | Completion Rate per Sprint               | The percentage of completed tasks out of the total planned.                                      | A general efficiency indicator for the sprint. |
|16 | Tasks Closed After Deadline per Sprint   | The percentage of tasks completed after the sprint deadline.                                     | Done tasks are finished in time. |
|17 | Task Throughput Over Time                | The number of Done tasks closed in each calendar week (ISO week format).                         | 1–3 tasks are completed each week. |
